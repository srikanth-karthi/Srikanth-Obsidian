### ğŸ”Â **What is Learning Rate in Machine Learning?**

**Learning rate**Â is a small decimal number (like 0.01 or 0.001) that controlsÂ **how big a step**Â the model takes toward minimizing the loss during each iteration ofÂ **gradient descent**.

---

### âš™ï¸Â **How It Works**

- At each training step, the model calculates theÂ **gradient**Â (slope) of the loss function.
    
- TheÂ **learning rate**Â is multiplied with the gradient to decide how much the modelâ€™s parameters (like weights and bias) should change.
    
    ParameterÂ update=âˆ’(learningÂ rate)Ã—(gradient)ParameterÂ update=âˆ’(learningÂ rate)Ã—(gradient)
    
    > Example: If the gradient isÂ **2.5**Â and learning rate isÂ **0.01**, the model updates the weight byÂ **0.025**.
    

---

### ğŸ¯Â **Why It Matters**

- **Too small**Â â†’ Training isÂ **very slow**, might take forever to converge.
    
- **Too large**Â â†’ Model mayÂ **overshoot**Â the minimum and never settle (it may oscillate or even diverge).
    
- **Just right**Â â†’ ModelÂ **converges efficiently**Â in fewer iterations.



next [[Bath Size]]