### ğŸ”„Â **What is an Epoch?**

AnÂ **epoch**Â isÂ **one complete pass**Â through theÂ **entire training dataset**.

For example:

- If you haveÂ **1,000 examples**Â and use aÂ **mini-batch size of 100**, it takesÂ **10 iterations**Â to completeÂ **1 epoch**.
    
- If you train forÂ **20 epochs**, the model will see each training exampleÂ **20 times**Â in total.
    

---

### ğŸ“ŠÂ **How Epochs Affect Training**

- **More epochs**Â generally allow the model to learn better (i.e.,Â **lower loss, better accuracy**).
    
- ButÂ **too many epochs**Â can lead toÂ **overfitting**â€”where the model performs well on training data but poorly on new, unseen data.
    
- **Early stopping**Â can be used to stop training when the model stops improving.
    

---

### âš™ï¸Â **Epochs, Batches, and Updates**

|Batch Type|When Updates Happen|Example (1,000 samples, 20 epochs)|
|---|---|---|
|**Full Batch**|Once per epoch|20 updates (1 per epoch)|
|**SGD (Batch = 1)**|Once per example|20,000 updates (1,000 Ã— 20)|
|**Mini-Batch (e.g., 100)**|Once per mini-batch|200 updates (10 per epoch Ã— 20)|